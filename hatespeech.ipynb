{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8076,"databundleVersionId":44219,"sourceType":"competition"}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn import metrics\nimport transformers\nimport torch\nfrom torch.utils.data import Dataset, DataLoader \nfrom transformers import DistilBertTokenizer, DistilBertModel\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:45:25.384205Z","iopub.execute_input":"2024-01-27T08:45:25.384557Z","iopub.status.idle":"2024-01-27T08:45:32.862599Z","shell.execute_reply.started":"2024-01-27T08:45:25.384530Z","shell.execute_reply":"2024-01-27T08:45:32.861588Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/sample_submission.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip\n/kaggle/input/jigsaw-toxic-comment-classification-challenge/test.csv.zip\n","output_type":"stream"}]},{"cell_type":"code","source":"from torch import cuda\ndevice = torch.device('cuda' if cuda.is_available() else 'cpu')\n\nprint(f\"Current device: {device}\")","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:45:32.863928Z","iopub.execute_input":"2024-01-27T08:45:32.864315Z","iopub.status.idle":"2024-01-27T08:45:32.898830Z","shell.execute_reply.started":"2024-01-27T08:45:32.864292Z","shell.execute_reply":"2024-01-27T08:45:32.897912Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Current device: cuda\n","output_type":"stream"}]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/jigsaw-toxic-comment-classification-challenge/train.csv.zip')\nprint(f\"Total Training Records : {len(train_data)}\")\n\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:45:40.251669Z","iopub.execute_input":"2024-01-27T08:45:40.252506Z","iopub.status.idle":"2024-01-27T08:45:41.825642Z","shell.execute_reply.started":"2024-01-27T08:45:40.252466Z","shell.execute_reply":"2024-01-27T08:45:41.824725Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Total Training Records : 159571\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                 id                                       comment_text  toxic  \\\n0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n\n   severe_toxic  obscene  threat  insult  identity_hate  \n0             0        0       0       0              0  \n1             0        0       0       0              0  \n2             0        0       0       0              0  \n3             0        0       0       0              0  \n4             0        0       0       0              0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>comment_text</th>\n      <th>toxic</th>\n      <th>severe_toxic</th>\n      <th>obscene</th>\n      <th>threat</th>\n      <th>insult</th>\n      <th>identity_hate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000997932d777bf</td>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000103f0d9cfb60f</td>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>000113f07ec002fd</td>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001b41b1c6bb37e</td>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001d958c54c6e35</td>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data.drop(['id'], inplace=True, axis=1)\ntrain_data['labels'] = train_data.iloc[:, 1:].values.tolist()\ntrain_data.drop(train_data.columns.values[1:-1].tolist(), inplace=True, axis=1)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:45:52.775155Z","iopub.execute_input":"2024-01-27T08:45:52.775510Z","iopub.status.idle":"2024-01-27T08:45:53.049203Z","shell.execute_reply.started":"2024-01-27T08:45:52.775483Z","shell.execute_reply":"2024-01-27T08:45:53.048340Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                        comment_text              labels\n0  Explanation\\nWhy the edits made under my usern...  [0, 0, 0, 0, 0, 0]\n1  D'aww! He matches this background colour I'm s...  [0, 0, 0, 0, 0, 0]\n2  Hey man, I'm really not trying to edit war. It...  [0, 0, 0, 0, 0, 0]\n3  \"\\nMore\\nI can't make any real suggestions on ...  [0, 0, 0, 0, 0, 0]\n4  You, sir, are my hero. Any chance you remember...  [0, 0, 0, 0, 0, 0]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>comment_text</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Explanation\\nWhy the edits made under my usern...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>D'aww! He matches this background colour I'm s...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey man, I'm really not trying to edit war. It...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>You, sir, are my hero. Any chance you remember...</td>\n      <td>[0, 0, 0, 0, 0, 0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data[\"comment_text\"] = train_data[\"comment_text\"].str.lower()\ntrain_data[\"comment_text\"] = train_data[\"comment_text\"].str.replace(\"\\xa0\", \" \", regex=False).str.split().str.join(\" \")","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:46:03.511855Z","iopub.execute_input":"2024-01-27T08:46:03.512923Z","iopub.status.idle":"2024-01-27T08:46:05.940892Z","shell.execute_reply.started":"2024-01-27T08:46:03.512874Z","shell.execute_reply":"2024-01-27T08:46:05.940053Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"MAX_LEN = 512\nTRAIN_BATCH_SIZE = 16\nEPOCHS = 1\nLEARNING_RATE = 1e-05\nNUM_WORKERS = 2","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:46:10.327017Z","iopub.execute_input":"2024-01-27T08:46:10.327387Z","iopub.status.idle":"2024-01-27T08:46:10.331968Z","shell.execute_reply.started":"2024-01-27T08:46:10.327356Z","shell.execute_reply":"2024-01-27T08:46:10.330990Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class MultiLabelDataset(Dataset):\n\n    def __init__(self, dataframe, tokenizer, max_len: int, eval_mode: bool = False):\n        self.data = dataframe\n        self.tokenizer = tokenizer\n        self.text = dataframe.comment_text\n        self.eval_mode = eval_mode \n        if self.eval_mode is False:\n            self.targets = self.data.labels\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, index):\n        text = str(self.text.iloc[index])\n        text = \" \".join(text.split())\n\n        inputs = self.tokenizer.encode_plus(\n            text,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n            return_token_type_ids=True\n        )\n        \n        ids = inputs['input_ids']\n        mask = inputs['attention_mask']\n        token_type_ids = inputs[\"token_type_ids\"]\n\n        output = {\n            'ids': torch.tensor(ids, dtype=torch.long),\n            'mask': torch.tensor(mask, dtype=torch.long),\n            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n        }\n                \n        if self.eval_mode is False:\n            output['targets'] = torch.tensor(self.targets.iloc[index], dtype=torch.float)\n                \n        return output","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:46:29.887314Z","iopub.execute_input":"2024-01-27T08:46:29.888275Z","iopub.status.idle":"2024-01-27T08:46:30.133017Z","shell.execute_reply.started":"2024-01-27T08:46:29.888232Z","shell.execute_reply":"2024-01-27T08:46:30.131919Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased', truncation=True, do_lower_case=True)\ntraining_set = MultiLabelDataset(train_data, tokenizer, MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:46:36.143534Z","iopub.execute_input":"2024-01-27T08:46:36.144253Z","iopub.status.idle":"2024-01-27T08:46:37.370396Z","shell.execute_reply.started":"2024-01-27T08:46:36.144223Z","shell.execute_reply":"2024-01-27T08:46:37.369628Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6815d8a7af12400e9b9ef3c1aa4b8d9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"652ec320fabb4a6dbd090edc5ca73c0f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a8f9f44555c4885a2f1efb0b89a972e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4445445fd9f4b0d966b3c94db4c899b"}},"metadata":{}}]},{"cell_type":"code","source":"train_params = {'batch_size': TRAIN_BATCH_SIZE,\n                'shuffle': True,\n                'num_workers': NUM_WORKERS\n                }\ntraining_loader = DataLoader(training_set, **train_params)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:46:57.518265Z","iopub.execute_input":"2024-01-27T08:46:57.519088Z","iopub.status.idle":"2024-01-27T08:46:57.523955Z","shell.execute_reply.started":"2024-01-27T08:46:57.519054Z","shell.execute_reply":"2024-01-27T08:46:57.522929Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class DistilBERTClass(torch.nn.Module):\n    \n    def __init__(self):\n        super(DistilBERTClass, self).__init__()\n        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.pre_classifier = torch.nn.Linear(768, 768)\n        self.dropout = torch.nn.Dropout(0.1)\n        self.classifier = torch.nn.Linear(768, 6)\n\n    def forward(self, input_ids, attention_mask, token_type_ids):\n        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n        hidden_state = output_1[0]\n        pooler = hidden_state[:, 0]\n        pooler = self.pre_classifier(pooler)\n        pooler = torch.nn.Tanh()(pooler)\n        pooler = self.dropout(pooler)\n        output = self.classifier(pooler)\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:47:06.303100Z","iopub.execute_input":"2024-01-27T08:47:06.303923Z","iopub.status.idle":"2024-01-27T08:47:06.311002Z","shell.execute_reply.started":"2024-01-27T08:47:06.303891Z","shell.execute_reply":"2024-01-27T08:47:06.310014Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"model = DistilBERTClass()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:47:15.808041Z","iopub.execute_input":"2024-01-27T08:47:15.808378Z","iopub.status.idle":"2024-01-27T08:47:17.637957Z","shell.execute_reply.started":"2024-01-27T08:47:15.808353Z","shell.execute_reply":"2024-01-27T08:47:17.637020Z"},"trusted":true},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce6356bc91994f768509fb60062efd6f"}},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"DistilBERTClass(\n  (l1): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=6, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    return torch.nn.BCEWithLogitsLoss()(outputs, targets)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:47:27.142343Z","iopub.execute_input":"2024-01-27T08:47:27.142845Z","iopub.status.idle":"2024-01-27T08:47:27.147455Z","shell.execute_reply.started":"2024-01-27T08:47:27.142811Z","shell.execute_reply":"2024-01-27T08:47:27.146467Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:47:33.979972Z","iopub.execute_input":"2024-01-27T08:47:33.980670Z","iopub.status.idle":"2024-01-27T08:47:33.985536Z","shell.execute_reply.started":"2024-01-27T08:47:33.980637Z","shell.execute_reply":"2024-01-27T08:47:33.984617Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train(epoch):\n    \n    model.train()\n    for _,data in tqdm(enumerate(training_loader, 0)):\n        ids = data['ids'].to(device, dtype = torch.long)\n        mask = data['mask'].to(device, dtype = torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype = torch.long)\n        targets = data['targets'].to(device, dtype = torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets)\n        if _%5000==0:\n            print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n        \n        loss.backward()\n        optimizer.step()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\ndef train(epoch):\n    model.train()\n    \n    # Create a tqdm progress bar for the training loader\n    tqdm_train_loader = tqdm(training_loader, desc=f'Epoch {epoch}', dynamic_ncols=True)\n    \n    for _, data in enumerate(tqdm_train_loader):\n        ids = data['ids'].to(device, dtype=torch.long)\n        mask = data['mask'].to(device, dtype=torch.long)\n        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n        targets = data['targets'].to(device, dtype=torch.float)\n\n        outputs = model(ids, mask, token_type_ids)\n\n        optimizer.zero_grad()\n        loss = loss_fn(outputs, targets)\n        \n        if _ % 9974 == 0:\n            print(f'Epoch: {epoch}, Loss: {loss.item()}')\n\n        loss.backward()\n        optimizer.step()\n        \n        # Update tqdm progress bar\n        tqdm_train_loader.set_postfix({'Loss': loss.item()})\n    \n    # Close the tqdm progress bar after completing the epoch\n    tqdm_train_loader.close()\n\n# Example usage in your training loop\nfor epoch in range(num_epochs):\n    train(epoch)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-27T08:49:43.451066Z","iopub.execute_input":"2024-01-27T08:49:43.451433Z","iopub.status.idle":"2024-01-27T09:59:51.652922Z","shell.execute_reply.started":"2024-01-27T08:49:43.451389Z","shell.execute_reply":"2024-01-27T09:59:51.651929Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"Epoch 0:   0%|          | 0/9974 [00:00<?, ?it/s]Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\nTruncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Epoch: 0, Loss: 0.6755465865135193\n","output_type":"stream"},{"name":"stderr","text":"Epoch 0: 100%|██████████| 9974/9974 [1:10:08<00:00,  2.37it/s, Loss=0.0531]  \n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:03:16.899457Z","iopub.execute_input":"2024-01-27T10:03:16.899845Z","iopub.status.idle":"2024-01-27T10:03:16.904284Z","shell.execute_reply.started":"2024-01-27T10:03:16.899816Z","shell.execute_reply":"2024-01-27T10:03:16.903297Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"Pkl_Filename = \"Pickle_RL_Model.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(model, file)\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2024-01-27T10:03:28.035716Z","iopub.execute_input":"2024-01-27T10:03:28.036804Z","iopub.status.idle":"2024-01-27T10:03:28.636220Z","shell.execute_reply.started":"2024-01-27T10:03:28.036771Z","shell.execute_reply":"2024-01-27T10:03:28.635460Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}